%! Author = noone
%! Date = 23/10/22

% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}

% Document
\begin{document}

\section{joint, marginal, conditional distributions}\label{sec:joint-marginal-conditional-distributions}
Optional video: Watch the below video for a brief review of multivariate functions.

khan academy video

A random vector \(\X = (X_1, X_2 \dots X_p)^T \in \mathbb{R}^p\, p \geq 2\) has a joint cdf

\[F_X (x) = P(X_1 \leq x_1, X_2 \leq x_2 ,\dots, X_p \leq x_p ) = F_X (x_1, x_2,\dots, x_p)\]

In case of a discreet vector of observations V the probability mass function is defined as

\[P_X(x) = P(X_1  = x_1, X_2 = x_2,\dots, X_p = x_p).\]

If a density \(f_{X} (x) = f_X (x_1, x_2 = x_2,\dots x_p\) exists such that

\[F_X (x) = \int_{-\infty} \dots \int_{x_p}*{-\infty} f_X (t)dt_1 \dots ft_p\]

then X is a continuous dandom vector with a joint density function of p arguments $$ From (0.12) we see that in this case $$ holds

the maring cdf of the first k < )
\section{Moments and density transformatin formula}\label{sec:moments-and-density-transformatin-formula}


\section{check your understanding}\label{sec:check-your-understanding}

\end{document}